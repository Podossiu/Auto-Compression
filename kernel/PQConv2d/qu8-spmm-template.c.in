// Copyright 2019 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert MR % 8 == 0
$assert NR in [1, 2, 4, 8]
$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01"
$assert DATATYPE in ["QS8", "QU8"]
$VMULADD_F32 = "vmla_f32"
$VMULADDQ_F32 = "vmlaq_f32"
$VMULADD_LANE_F32 = "vmla_lane_f32"
$VMULADDQ_LANE_F32 = "vmlaq_lane_f32"


$PARAMS_UNION = "xnn_qs8_minmax_params" if DATATYPE == "QC8" else "xnn_%s_conv_minmax_params" % DATATYPE.lower()
$XINT8_T = "uint8_t" if DATATYPE == "QU8" else "int8_t"
$XINT8X8_T = "uint8x8_t" if DATATYPE == "QU8" else "int8x8_t"
$XINT8X16_T = "uint8x16_t" if DATATYPE == "QU8" else "int8x16_t"
$VGET_LOW_X8 = "vget_low_u8" if DATATYPE == "QU8" else "vget_low_s8"
$VGET_HIGH_X8 = "vget_high_u8" if DATATYPE == "QU8" else "vget_high_s8"
$VCOMBINE_X8 = "vcombine_u8" if DATATYPE == "QU8" else "vcombine_s8"
$VREINTERPRET_U32_X8 = "vreinterpret_u32_u8" if DATATYPE == "QU8" else "vreinterpret_u32_s8"
$VREINTERPRETQ_U32_X8 = "vreinterpretq_u32_u8" if DATATYPE == "QU8" else "vreinterpretq_u32_s8"
$VREINTERPRET_U16_X8 = "vreinterpret_u16_u8" if DATATYPE == "QU8" else "vreinterpret_u16_s8"
$VREINTERPRETQ_U16_X8 = "vreinterpretq_u16_u8" if DATATYPE == "QU8" else "vreinterpretq_u16_s8"
$VREINTERPRETQ_X8_S16 = "vreinterpretq_u8_s16" if DATATYPE == "QU8" else "vreinterpretq_s8_s16"
$VLD1_X8 = "vld1_u8" if DATATYPE == "QU8" else "vld1_s8"
$VLD1_DUP_X8 = "vld1_dup_u8" if DATATYPE == "QU8" else "vld1_dup_s8"
$VLD1Q_DUP_X8 = "vld1q_dup_u8" if DATATYPE == "QU8" else "vld1q_dup_s8"
$VST1_X8 = "vst1_u8" if DATATYPE == "QU8" else "vst1_s8"
$VST1Q_X8 = "vst1q_u8" if DATATYPE == "QU8" else "vst1q_s8"
$VST1_LANE_X8 = "vst1_lane_u8" if DATATYPE == "QU8" else "vst1_lane_s8"
$VST1Q_LANE_X8 = "vst1q_lane_u8" if DATATYPE == "QU8" else "vst1q_lane_s8"
$VMIN_X8 = "vmin_u8" if DATATYPE == "QU8" else "vmin_s8"
$VMAX_X8 = "vmax_u8" if DATATYPE == "QU8" else "vmax_s8"
$VMINQ_X8 = "vminq_u8" if DATATYPE == "QU8" else "vminq_s8"
$VMAXQ_X8 = "vmaxq_u8" if DATATYPE == "QU8" else "vmaxq_s8"
$VEXT_X8 = "vext_u8" if DATATYPE == "QU8" else "vext_s8"
$VEXTQ_X8 = "vextq_u8" if DATATYPE == "QU8" else "vextq_s8"
$VQMOVXN_S16 = "vqmovun_s16" if DATATYPE == "QU8" else "vqmovn_s16"
$VQMOVXN_HIGH_S16 = "vqmovun_high_s16" if DATATYPE == "QU8" else "vqmovn_high_s16"
$VMOVN_X16 = "vmovn_u16" if DATATYPE == "QU8" else "vmovn_s16"
$VUZP1Q_X8 = "vuzp1q_u8" if DATATYPE == "QU8" else "vuzp1q_s8"

#include <assert.h>

#include <arm_neon.h>

#include <xnnpack/spmm.h>


void xnn_${DATATYPE.lower()}_spmm_minmax_ukernel_${MR}x${NR}__${"neon"}(
    size_t mc,
    size_t nc,
    const ${XINT8_T}*restrict input,
    const ${XINT8_T}*restrict weights,
    const int32_t*restrict widx_dmap,
    const uint32_t*restrict nidx_nnzmap,
    ${XINT8_T}*restrict output,
    size_t output_stride,
    const union xnn_${DATATYPE.lower()}_conv_minmax_params params[restrict XNN_MIN_ELEMENTS(1)]) XNN_OOB_READS
{
  assert(mc != 0);
  assert(mc % sizeof(float) == 0);
  assert(nc != 0);

  //const float32x4_t vmin = vld1q_dup_f32(&params->scalar.min);
  //const float32x4_t vmax = vld1q_dup_f32(&params->scalar.max);
  const uint8x8_t vw_zero_point = vld1_dup_u8(&params->rndnu_neon.kernel_zero_point[0]);
  size_t output_decrement = output_stride * nc - ${MR} * sizeof(${XINT8_T});
  while XNN_LIKELY(mc >= ${MR} * sizeof(${XINT8_T})) {
    const ${XINT8_T}*restrict w = weights;
    const int32_t* dmap = widx_dmap;
    const uint32_t* nnzmap = nidx_nnzmap;
    size_t n = nc;
    while (n >= ${NR}) {
      uint32_t nnz = *nnzmap++;
      $for N in range(0, NR, 1):
        int32x4_t vacc${ABC[0:4]}n${N} = vld1q_dup_s32(w); w = (const void*) ((const int32_t*) w + 1);
        $for M in range(4, MR, 4):
          int32x4_t vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};
      if XNN_LIKELY(nnz != 0) {
        do {
          const intptr_t diff = *dmap++;
          const ${XINT8X8_T} vi${ABC[0:8]} = ${VLD1_X8}(input);
          const int16x8_t vxi${ABC[0:8]} = vreinterpretq_s16_u16(vmovl_u8(vi${ABC[0:8]}));
          $for M in range(8, MR, 8):
            const ${XINT8X8_T} vi${ABC[M:M+8]} = ${VLD1_X8}(input + ${M});
            const int16x8_t vxi${ABC[M:M+8]} = vreinterpretq_s16_u16(vmovl_u8(vi${ABC[M:M+8]}));
          input = (const ${XINT8_T}*restrict) ((uintptr_t) input + (uintptr_t) diff);
          $for M in range(0, MR, 16):
            __builtin_prefetch(input + ${M+16});
          $if NR < 8:
            ${XINT8X8_T} vw = ${VLD1_DUP_X8}(w); w = (const void*) ((const ${XINT8_T}*) w + 1);
            $for N in range(1, NR, 1):
              vw = vld1_lane_u8(w, vw, ${N}); w = (const void*) ((const ${XINT8_T}*) w + 1);
          $else:
            const ${XINT8X8_T} vw = ${VLD1_X8}(w); w = (const void*) ((const ${XINT8_T}*) w + ${NR});
          $if DATATYPE == "QU8":
            const int16x8_t vxw = vreinterpretq_s16_u16(vsubl_u8(vw, vw_zero_point));
          $else:
            const int16x8_t vxw = vmovl_s8(vw);
          __builtin_prefetch((const void*) ((const ${XINT8_T}*) w + 32));
          $if NR == 1:
            $for M in range(0, MR, 8):
              vacc${ABC[M:M+4]}n0 = vmlal_s16(vacc${ABC[M:M+4]}n0, vget_low_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw));
              vacc${ABC[M+4:M+8]}n0 = vmlal_s16(vacc${ABC[M+4:M+8]}n0, vget_high_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw));
          $else:
            $for N in range(NR):
              $for M in range(0, MR, 8):
                $if N < 4:
                  vacc${ABC[M:M+4]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_low_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw), ${N});
                  vacc${ABC[M+4:M+8]}n${N} = vmlal_lane_s16(vacc${ABC[M+4:M+8]}n${N}, vget_high_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw), ${N});
                $else:
                  vacc${ABC[M:M+4]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_low_s16(vxi${ABC[M:M+8]}), vget_high_s16(vxw), ${N-4});
                  vacc${ABC[M+4:M+8]}n${N} = vmlal_lane_s16(vacc${ABC[M+4:M+8]}n${N}, vget_high_s16(vxi${ABC[M:M+8]}), vget_high_s16(vxw), ${N-4});
        } while (--nnz != 0);
      }

      const int32x4_t vright_pre_shift = vld1q_dup_s32(&params->rndnu_neon.right_pre_shift);
      const int32x4_t vmultiplier = vld1q_dup_s32(&params->rndnu_neon.multiplier);
      const int32x4_t vright_post_shift = vld1q_dup_s32(&params->rndnu_neon.right_post_shift);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 4):
          vacc${ABC[M:M+4]}n${N} = vshlq_s32(vacc${ABC[M:M+4]}n${N}, vright_pre_shift);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 4):
          vacc${ABC[M:M+4]}n${N} = vqdmulhq_s32(vacc${ABC[M:M+4]}n${N}, vmultiplier);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 4):
          vacc${ABC[M:M+4]}n${N} = vrshlq_s32(vacc${ABC[M:M+4]}n${N}, vright_post_shift);

      const int16x8_t voutput_zero_point = vld1q_dup_s16(&params->rndnu_neon.output_zero_point);
      $for N in range(0, NR, 1):
        $for M in range(0, MR, 8):
          const int16x8_t vacc${ABC[M:M+8]}n${N} = vqaddq_s16(vcombine_s16(vqmovn_s32(vacc${ABC[M:M+4]}n${N}), vqmovn_s32(vacc${ABC[M+4:M+8]}n${N})), voutput_zero_point);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 8):
          ${XINT8X8_T} vout${ABC[M:M+8]}n${N} = ${VQMOVXN_S16}(vacc${ABC[M:M+8]}n${N});

      const ${XINT8X8_T} voutput_min = ${VLD1_DUP_X8}(&params->rndnu_neon.output_min);
      const ${XINT8X8_T} voutput_max = ${VLD1_DUP_X8}(&params->rndnu_neon.output_max);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 8):
          vout${ABC[M:M+8]}n${N} = ${VMAX_X8}(vout${ABC[M:M+8]}n${N}, voutput_min);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 8):
          vout${ABC[M:M+8]}n${N} = ${VMIN_X8}(vout${ABC[M:M+8]}n${N}, voutput_max);

      $for N in range(0, NR, 1):
        $for M in range(0, MR, 8):
          ${VST1_X8}(output + ${M}, vout${ABC[M:M+8]}n${N});
        output = (${XINT8_T}*restrict) ((uintptr_t) output + output_stride);

      n -= ${NR};
    }

    output = (${XINT8_T}*restrict) ((uintptr_t) output - output_decrement);
    input += ${MR};
    mc -= ${MR} * sizeof(${XINT8_T});
  }
  if XNN_UNLIKELY(mc != 0) {
    $for LOG2M in reversed(range((MR - 1).bit_length())):
      $SUBMR = 1 << LOG2M
      $if SUBMR * 2 >= MR:
        output_decrement += ${MR - SUBMR} * sizeof(${XINT8_T});
      $else:
        output_decrement += ${SUBMR} * sizeof(${XINT8_T});
      if (mc & (${SUBMR} * sizeof(${XINT8_T}))) {
        const ${XINT8_T}*restrict w = weights;
        const int32_t* dmap = widx_dmap;
        const uint32_t* nnzmap = nidx_nnzmap;
        size_t n = nc;
        while (n >= ${NR}) {
          uint32_t nnz = *nnzmap++;
          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              int32x4_t vacc${ABC[0:SUBMR]}n${N} = vld1q_dup_s32(w); w = (const void*) ((const int32_t*) w + 1);
            $else:
              int32x4_t vacc${ABC[0:4]}n${N} = vld1q_dup_s32(w); w = (const void*) ((const int32_t*) w + 1);
            $for M in range(4, SUBMR, 4):
              int32x4_t vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};
          if XNN_LIKELY(nnz != 0) {
            do {
              const intptr_t diff = *dmap++;
              $if SUBMR < 8:
                ${XINT8X8_T} vi${ABC[0:SUBMR]} = ${VLD1_DUP_X8}(input);
                $for S in range(1, SUBMR, 1):
                  vi${ABC[0:SUBMR]} = vld1_lane_u8(input+${S}, vi${ABC[0:SUBMR]}, ${S});
                const int16x8_t vxi${ABC[0:SUBMR]} = vreinterpretq_s16_u16(vmovl_u8(vi${ABC[0:SUBMR]}));
              $else:
                const ${XINT8X8_T} vi${ABC[0:8]} = ${VLD1_X8}(input);
                const int16x8_t vxi${ABC[0:8]} = vreinterpretq_s16_u16(vmovl_u8(vi${ABC[0:8]}));
                $for M in range(8, SUBMR, 8):
                  const ${XINT8X8_T} vi${ABC[M:M+8]} = ${VLD1_X8}(input + ${M});
                  const int16x8_t vxi${ABC[M:M+8]} = vreinterpretq_s16_u16(vmovl_u8(vi${ABC[M:M+8]}));
              input = (const ${XINT8_T}*restrict) ((uintptr_t) input + (uintptr_t) diff);
              $if NR < 8:
                ${XINT8X8_T} vw = ${VLD1_DUP_X8}(w); w = (const void*) ((const ${XINT8_T}*) w + 1);
                $for N in range(1, NR, 1):
                  vw = vld1_lane_u8(w, vw, ${N}); w = (const void*) ((const ${XINT8_T}*) w + 1);
              $else:
                const ${XINT8X8_T} vw = ${VLD1_X8}(w); w = (const void*) ((const ${XINT8_T}*) w + ${NR});
              $if DATATYPE == "QU8":
                const int16x8_t vxw = vreinterpretq_s16_u16(vsubl_u8(vw, vw_zero_point));
              $else:
                const int16x8_t vxw = vmovl_s8(vw);

              $if NR == 1:
                $if SUBMR < 8:
                  vacc${ABC[0:SUBMR]}n0 = vmlal_s16(vacc${ABC[0:SUBMR]}n0, vget_low_s16(vxi${ABC[0:SUBMR]}), vget_low_s16(vxw));
                $else:
                  $for M in range(0, SUBMR, 8):
                    vacc${ABC[M:M+4]}n0 = vmlal_s16(vacc${ABC[M:M+4]}n0, vget_low_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw));
                    vacc${ABC[M+4:M+8]}n0 = vmlal_s16(vacc${ABC[M+4:M+8]}n0, vget_high_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw));
                    
              $else:
                $for N in range(NR):
                  $if SUBMR < 8:
                    $if N < 4:
                      vacc${ABC[0:SUBMR]}n${N} = vmlal_lane_s16(vacc${ABC[0:SUBMR]}n${N}, vget_low_s16(vxi${ABC[0:SUBMR]}), vget_low_s16(vxw), ${N});
                    $else:
                      vacc${ABC[0:SUBMR]}n${N} = vmlal_lane_s16(vacc${ABC[0:SUBMR]}n${N}, vget_low_s16(vxi${ABC[0:SUBMR]}), vget_low_s16(vxw), ${N-4});
                  $else:
                    $for M in range(0, SUBMR, 8):
                      $if N < 4:
                        vacc${ABC[M:M+4]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_low_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw), ${N});
                        vacc${ABC[M+4:M+8]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_high_s16(vxi${ABC[M:M+8]}), vget_low_s16(vxw), ${N});
                      $else:
                        vacc${ABC[M:M+4]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_low_s16(vxi${ABC[M:M+8]}), vget_high_s16(vxw), ${N-4});
                        vacc${ABC[M+4:M+8]}n${N} = vmlal_lane_s16(vacc${ABC[M:M+4]}n${N}, vget_high_s16(vxi${ABC[M:M+8]}), vget_high_s16(vxw), ${N-4});
            } while (--nnz != 0);
          }
          
          const int32x4_t vright_pre_shift = vld1q_dup_s32(&params->rndnu_neon.right_pre_shift);
          const int32x4_t vmultiplier = vld1q_dup_s32(&params->rndnu_neon.multiplier);
          const int32x4_t vright_post_shift = vld1q_dup_s32(&params->rndnu_neon.right_post_shift);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              vacc${ABC[0:SUBMR]}n${N} = vshlq_s32(vacc${ABC[0:SUBMR]}n${N}, vright_pre_shift);
            $else:
              $for M in range(0, SUBMR, 4):
                vacc${ABC[M:M+4]}n${N} = vshlq_s32(vacc${ABC[M:M+4]}n${N}, vright_pre_shift);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              vacc${ABC[0:SUBMR]}n${N} = vqdmulhq_s32(vacc${ABC[0:SUBMR]}n${N}, vmultiplier);
            $else:
              $for M in range(0, SUBMR, 4):
                vacc${ABC[M:M+4]}n${N} = vqdmulhq_s32(vacc${ABC[M:M+4]}n${N}, vmultiplier);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              vacc${ABC[0:SUBMR]}n${N} = vrshlq_s32(vacc${ABC[0:SUBMR]}n${N}, vright_post_shift);
            $else:
              $for M in range(0, SUBMR, 4):
                vacc${ABC[M:M+4]}n${N} = vrshlq_s32(vacc${ABC[M:M+4]}n${N}, vright_post_shift);

          const int16x8_t voutput_zero_point = vld1q_dup_s16(&params->rndnu_neon.output_zero_point);
          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              const int16x8_t vacc${ABC[0:SUBMR]}${ABC[0:SUBMR]}n${N} = vqaddq_s16(vcombine_s16(vqmovn_s32(vacc${ABC[0:SUBMR]}n${N}), vqmovn_s32(vacc${ABC[0:SUBMR]}n${N})), voutput_zero_point);
            $else:
              $for M in range(0, SUBMR, 8):
                const int16x8_t vacc${ABC[M:M+8]}n${N} = vqaddq_s16(vcombine_s16(vqmovn_s32(vacc${ABC[M:M+4]}n${N}), vqmovn_s32(vacc${ABC[M+4:M+8]}n${N})), voutput_zero_point);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              ${XINT8X8_T} vout${ABC[0:SUBMR]}n${N} = ${VQMOVXN_S16}(vacc${ABC[0:SUBMR]}${ABC[0:SUBMR]}n${N});
            $else: 
              $for M in range(0, SUBMR, 8):
                ${XINT8X8_T} vout${ABC[M:M+8]}n${N} = ${VQMOVXN_S16}(vacc${ABC[M:M+8]}n${N});

          const ${XINT8X8_T} voutput_min = ${VLD1_DUP_X8}(&params->rndnu_neon.output_min);
          const ${XINT8X8_T} voutput_max = ${VLD1_DUP_X8}(&params->rndnu_neon.output_max);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              vout${ABC[0:SUBMR]}n${N} = ${VMAX_X8}(vout${ABC[0:SUBMR]}n${N}, voutput_min);
            $else:
              $for M in range(0, SUBMR, 8):
                vout${ABC[M:M+8]}n${N} = ${VMAX_X8}(vout${ABC[M:M+8]}n${N}, voutput_min);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              vout${ABC[0:SUBMR]}n${N} = ${VMIN_X8}(vout${ABC[0:SUBMR]}n${N}, voutput_max);
            $else:
              $for M in range(0, SUBMR, 8):
                vout${ABC[M:M+8]}n${N} = ${VMIN_X8}(vout${ABC[M:M+8]}n${N}, voutput_max);

          $for N in range(0, NR, 1):
            $if SUBMR < 8:
              $for M in range(0, SUBMR, 1):
                vst1_lane_u8(output + ${M}, vout${ABC[0:SUBMR]}n${N}, ${M});
            $else:
              $for M in range(0, SUBMR, 8):
                ${VST1_X8}(output + ${M}, vout${ABC[M:M+8]}n${N});
            output = (${XINT8_T}*restrict) ((uintptr_t) output + output_stride);

          n -= ${NR};
        }

        output = (${XINT8_T}*restrict) ((uintptr_t) output - output_decrement);
        input += ${SUBMR};
      }
    }
}
